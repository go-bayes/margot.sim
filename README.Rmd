---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# margot.sim

<!-- badges: start -->
<!-- badges: end -->

R package for simulating longitudinal data with realistic observational shadows (measurement error, missingness, selection bias) and evaluating causal inference methods via Monte Carlo simulation.

## Installation

You can install the development version of margot.sim from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("go-bayes/margot.sim")
```

## Overview

margot.sim extends the `margot` package with:

1. **Shadowing Framework** - Apply observational distortions (measurement error, missingness, selection bias)
2. **Monte Carlo Framework** - Systematically evaluate statistical estimators  
3. **Flexible Distributions** - Specify non-normal distributions
4. **Integrated Workflows** - Complete simulation studies

## Quick Start

```{r example, eval=FALSE}
library(margot.sim)

# Generate data with measurement error
shadow <- create_shadow(
  type = "measurement_error",
  params = list(
    variables = c("t1_l", "t2_l"),
    error_type = "classical",
    sigma = 0.5
  )
)

dat <- margot_simulate(
  n = 1000,
  waves = 3,
  shadows = shadow
)

# Run Monte Carlo evaluation
mc_results <- margot_monte_carlo(
  n_reps = 100,
  n_per_rep = 500,
  dgp_params = list(waves = 2),
  shadows = list(shadow),
  estimator_fn = function(data) {
    fit <- lm(t3_y ~ t2_a + t1_l + b1, data = data)
    list(
      estimate = coef(fit)["t2_a"],
      se = sqrt(diag(vcov(fit)))["t2_a"]
    )
  }
)

print(mc_results)
```

## Shadowing Framework

### Available Shadow Types

**Measurement Error:**
- Classical error (continuous variables)
- Misclassification (binary variables) 
- Differential error
- Dichotomization
- Correlated errors

```{r measurement-error, eval=FALSE}
# Classical measurement error
me_shadow <- create_shadow(
  type = "measurement_error",
  params = list(
    variables = "t1_l",
    error_type = "classical",
    sigma = 0.5
  )
)

# Misclassification for binary variables
misclass_shadow <- create_shadow(
  type = "measurement_error", 
  params = list(
    variables = "t1_a",
    error_type = "misclassification",
    sensitivity = 0.85,  # P(observed=1|true=1)
    specificity = 0.90   # P(observed=0|true=0)
  )
)
```

**Missing Data:**
```{r missingness, eval=FALSE}
# Item-level missingness
miss_shadow <- create_item_missingness_shadow(
  variables = c("t1_l", "t2_l"),
  missing_rate = 0.2,
  missing_mechanism = "MAR",
  dependent_vars = "b1"
)
```

**Selection Bias:**
```{r selection, eval=FALSE}
# Positivity violations
pos_shadow <- create_positivity_shadow(
  exposure_var = "t1_a",
  filter_fn = function(data) {
    # Treatment only possible if risk score <= 2
    data$b1 + data$b2 <= 2
  }
)
```

### Combining Shadows

```{r combining, eval=FALSE}
# Apply multiple shadows
shadows <- list(me_shadow, miss_shadow)
dat <- margot_simulate(n = 1000, waves = 3, shadows = shadows)

# Or apply post-hoc
shadowed_data <- apply_shadows(dat, shadows)
```

## Monte Carlo Framework

Evaluate estimator performance under various conditions:

```{r monte-carlo, eval=FALSE}
# Define estimator
ipw_estimator <- function(data) {
  # Fit propensity score model
  ps_model <- glm(t1_a ~ b1 + b2 + t0_l, 
                  data = data, 
                  family = binomial)
  ps <- predict(ps_model, type = "response")
  
  # Calculate weights
  weights <- ifelse(data$t1_a == 1, 1/ps, 1/(1-ps))
  
  # Outcome model
  fit <- lm(t2_y ~ t1_a, weights = weights, data = data)
  
  list(
    estimate = coef(fit)["t1_a"],
    se = sqrt(diag(vcov(fit)))["t1_a"],
    converged = TRUE
  )
}

# Run simulation
results <- margot_monte_carlo(
  n_reps = 500,
  n_per_rep = 1000,
  dgp_params = list(
    waves = 2,
    params = list(a_lag_y_coef = 0.3)  # True effect
  ),
  shadows = list(me_shadow, miss_shadow),
  estimator_fn = ipw_estimator,
  truth_fn = function(data) 0.3,
  parallel = TRUE,
  n_cores = 4
)

# View results
print(results)
plot(results, type = "histogram")
```

### Performance Metrics

The framework automatically calculates:
- Bias and relative bias
- Variance and MSE
- Coverage of confidence intervals
- Convergence rates
- Sample size retention

## Complete Example

```{r complete-example, eval=FALSE}
# Compare estimators under measurement error
comparison <- example_measurement_error_comparison()

# Full workflow demonstration
results <- example_complete_workflow()
```

## Advanced Usage

### Custom Shadows

Create your own shadow types:

```{r custom-shadow, eval=FALSE}
# Define apply method
apply_shadow.my_custom_shadow <- function(data, shadow, ...) {
  # Your shadowing logic here
  data
}

# Use it
shadow <- structure(
  list(type = "my_custom", params = list(...)),
  class = c("my_custom_shadow", "margot_shadow")
)
```

### Flexible Distributions

```{r distributions, eval=FALSE}
# Non-normal baseline
gamma_dist <- create_distribution(
  "gamma",
  params = list(shape = 2, rate = 1)
)

# Use in simulation
dat <- margot_simulate_flex(
  n = 1000,
  distributions = list(baseline = gamma_dist)
)
```

## Documentation

For detailed documentation, see:

```{r help, eval=FALSE}
# Package documentation
?margot.sim

# Key functions
?create_shadow
?margot_monte_carlo
?margot_simulate

# Examples
example(create_shadow)
example(margot_monte_carlo)
```

## Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Submit a pull request

## License

MIT License

## Citation

If you use margot.sim in your research, please cite:

```{r citation, eval=FALSE}
citation("margot.sim")
```
