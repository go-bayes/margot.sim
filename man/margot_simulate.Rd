% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/margot-simulate-core.R
\name{margot_simulate}
\alias{margot_simulate}
\title{Simulate semi-markovian longitudinal data with sampling weights}
\usage{
margot_simulate(
  n,
  waves,
  n_outcomes = 1,
  n_baselines = 5,
  exposure_type = "binary",
  outcome_type = "continuous",
  y_feedback = c("full", "y_only", "none"),
  censoring = list(rate = 0.1, exposure_dependence = TRUE, l_dependence = FALSE,
    y_dependence = FALSE, latent_dependence = FALSE),
  params = list(),
  seed = NULL,
  wide = TRUE,
  validate_props = TRUE,
  verbose = FALSE,
  intervention = NULL,
  sampling_weights = NULL,
  apply_process_function = TRUE,
  process_args = list(),
  shadows = NULL
)
}
\arguments{
\item{n}{Integer. Number of subjects to simulate}

\item{waves}{Integer. Number of measurement waves (time points)}

\item{n_outcomes}{Integer. Number of outcomes (1-3). Default: 1}

\item{n_baselines}{Integer. Number of baseline covariates. Default: 5}

\item{exposure_type}{Character. Type of exposure: "binary" or "continuous". Default: "binary"}

\item{outcome_type}{Character. Type of outcome: "continuous" or "binary". Default: "continuous"}

\item{y_feedback}{Character. Type of outcome feedback: "full", "y_only", or "none". Default: "full"}

\item{censoring}{List. Censoring parameters including rate, exposure_dependence, l_dependence, y_dependence, latent_dependence}

\item{params}{List. Named list of model parameters (see defaults in .default_sim_params()).
Key heterogeneity parameters include:
\itemize{
  \item \code{a_b1_y_het}, \code{a_b2_y_het}, \code{a_b3_y_het}: Effect modification by baseline covariates
  \item \code{a_y0_y_het}: Effect modification by baseline outcome (when y_feedback != "none")
  \item \code{a_a0_y_het}: Effect modification by baseline exposure
  \item \code{a_b_y_het}: Legacy parameter for b1 interaction (kept for compatibility)
  \item \code{a_l_y_het}: Effect modification by time-varying confounder
}}

\item{seed}{Integer. Random seed for reproducibility}

\item{wide}{Logical. Return data in wide format? Default: TRUE}

\item{validate_props}{Logical. Validate that coefficients sum to < 1? Default: TRUE}

\item{verbose}{Logical. Print progress messages? Default: FALSE}

\item{intervention}{Function. Intervention function(data, time, trt) that modifies treatment}

\item{sampling_weights}{Numeric vector of length n, or function(baseline_data)
that returns weights. Used to weight baseline covariates to reflect
target population. If NULL, no weighting is applied.}

\item{apply_process_function}{Logical. If TRUE, applies
margot_process_longitudinal to create proper censoring indicators}

\item{process_args}{List of arguments to pass to margot_process_longitudinal}

\item{shadows}{A shadow object or list of shadow objects created with
\code{create_shadow()} or related functions. Shadows are applied after data
generation and processing to simulate observational distortions like
measurement error, missingness, or selection bias.}
}
\value{
A tibble with columns for:
  - \code{id}: Subject identifier
  - \code{b1, ..., bn}: Baseline covariates
  - \code{t0_a, t1_a, ...}: Treatment assignments (natural or under intervention)
  - \code{t1_l, t2_l, ...}: Time-varying confounders
  - \code{t0_y, t1_y, ..., t(K+1)_y}: Outcomes
  - \code{t*_not_lost_following_wave}: Censoring indicators (if apply_process_function = TRUE)
  - \code{sampling_weight}: Applied weights (if sampling_weights provided)

The returned object has attribute "margot_meta" containing simulation parameters.
}
\description{
Generates data following a semi-markovian structural causal model (SCM) with:
- Semi-markovian data generating process
- Optional sampling weights to reflect target population
- Intervention functions for causal inference
- Post-hoc censoring for bias analysis

The function cleanly separates three stages:
1. Data generation under intervention g (if specified): \eqn{(B, L_k^g, A_k^g, Y_k^g)}
2. Application of sampling weights to match target population
3. Creation of censoring indicators: \eqn{C_k} (via margot_process_longitudinal)

This mirrors counterfactual notation: \eqn{A_k \to A_k^g, C_k \equiv 0, Y_K^{g,C=0}}
}
\section{Directed Acyclic Graph (DAG)}{

The data generating process follows this DAG structure:
\preformatted{
    B --+---> L_1 ---> A_1 ---> Y_1 ---> L_2 ---> A_2 ---> Y_2 ---> ... ---> Y_K
        |      |      |      |      |      |      |
        |      v      v      v      v      v      v
        +----> C_1     C_2     C_3    C_4     C_5     C_6

Where:
  B  = Baseline covariates (time-invariant)
  L_k = Time-varying confounders at wave k
  A_k = Exposure/treatment at wave k
  Y_k = Outcome(s) at wave k
  C_k = Censoring indicator after wave k
}
}

\section{Structural Equations}{

The SCM is defined by the following structural equations.

For baseline (k=0):
\deqn{B \sim \text{MVN}(0, \Sigma_B) \text{ with } \Sigma_B[i,j] = \rho_B \text{ if } i \neq j}
\deqn{A_0 = f_{A_0}(B, U_{A_0})}
\deqn{Y_0 = f_{Y_0}(B, A_0, U_{Y_0})}

For wave k >= 1:
\deqn{L_k = \beta_{B \to L} \cdot h_k(B) + \beta_{A \to L} A_{k-1} + \beta_{Y \to L} Y_{k-1} + U_{L_k}}
\deqn{A_k = f_{A_k}(B, L_k, A_{k-1}, Y_{k-1}, U_{A_k})}
\deqn{Y_k = f_{Y_k}(B, L_{k-1}, A_{k-1}, Y_{k-1}, U_{Y_k})}
\deqn{C_k = f_{C_k}(A_{k-1}, L_{k-1}, Y_{k-1}, \theta, U_{C_k})}

Where:
- \eqn{h_k(B)} represents time-varying functions of baseline covariates
- \eqn{U_{\cdot} \sim N(0,1)} are independent errors except as noted below
- \eqn{\theta} is a shared frailty term when latent_dependence = TRUE
}

\section{Unmeasured Confounding}{

The following unmeasured confounding structures are supported:

1. **Independent errors** (default): All \eqn{U_{\cdot}} are mutually independent

2. **Shared frailty for censoring**: When \code{latent_dependence = TRUE},
   \deqn{\theta \sim N(0, \sigma^2_{\text{frailty}})}
   affects all censoring events, inducing correlation in dropout times

3. **Correlated outcomes**: When \code{n_outcomes > 1},
   \deqn{U_{Y_k} \sim \text{MVN}(0, \Sigma_Y)}
   where \eqn{\Sigma_Y} has off-diagonal elements \code{y_cor}

Note: There is no unmeasured confounding between treatment and outcome by design.
All confounding passes through measured variables (B, L).
}

\section{Parameter Interpretation}{

Key parameters in the structural equations:
- \code{b_l_coef}: \eqn{\beta_{B \to L}} effect of baseline on time-varying confounder
- \code{a_l_coef}: \eqn{\beta_{A \to L}} effect of past treatment on confounder
- \code{y_l_coef}: \eqn{\beta_{Y \to L}} feedback from past outcome to confounder
- \code{l_a_coef}: \eqn{\beta_{L \to A}} effect of confounder on treatment
- \code{a_autoreg}: \eqn{\beta_{A \to A}} treatment persistence
- \code{a_lag_y_coef}: \eqn{\beta_{A \to Y}} causal effect of treatment on outcome
- \code{cens_*_coef}: Effects on censoring hazard
}

\examples{
# basic simulation following the SCM
dat <- margot_simulate(
  n = 1000,
  waves = 3,
  seed = 2025
)

# with intervention g: always treat after baseline
dat_g <- margot_simulate(
  n = 1000,
  waves = 3,
  intervention = function(data, time, trt) {
    if (time == 0) return(data[[trt]])  # natural at baseline
    rep(1, nrow(data))                   # always treat after
  },
  seed = 2025
)

# the estimand E[Y_K^{g,C=0}] can be computed as mean(dat_g$t4_y)

# Example with shadows
# Create measurement error shadow
me_shadow <- create_shadow(
  "measurement_error",
  params = list(
    variables = c("t1_l", "t2_l"),
    error_type = "classical",
    sigma = 0.5
  )
)

# Generate data with measurement error
dat_with_error <- margot_simulate(
  n = 1000,
  waves = 2,
  shadows = me_shadow,
  seed = 2025
)
# shadowed data has measurement error applied to specified variables

}
\references{
Robins JM (1986). "A new approach to causal inference in mortality studies
with sustained exposure periods--application to control of the healthy worker
survivor effect." Mathematical Modelling, 7(9-12), 1393-1512.

Hernan MA, Robins JM (2020). "Causal Inference: What If."
Boca Raton: Chapman & Hall/CRC.
}
