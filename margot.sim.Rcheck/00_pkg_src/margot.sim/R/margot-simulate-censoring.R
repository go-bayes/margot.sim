#' Apply censoring to complete data
#'
#' @description
#' Takes data generated by margot_simulate and applies censoring based on
#' the stored censoring probabilities or a custom censoring function.
#' 
#' @details
#' ## Censoring Logic
#' 
#' When a subject is censored at wave k:
#' 1. All variables from wave k onwards are set to NA
#' 2. The subject is considered "lost to follow-up" from that point
#' 3. No future data is observed for that subject
#' 
#' ## Not-Lost Indicators
#' 
#' When `apply_process_function = TRUE`, the function creates "not_lost" indicators:
#' - `t0_not_lost_following_wave`: 1 if subject has data at t1, 0 otherwise
#' - `t1_not_lost_following_wave`: 1 if subject has data at t2, 0 otherwise
#' - And so on...
#' 
#' These indicators are useful for:
#' - Inverse probability of censoring weights (IPCW)
#' - Determining the at-risk population at each wave
#' - Creating proper denominators for survival analyses
#' 
#' ## Important Note
#' 
#' Unlike some implementations, this function does NOT carry forward last
#' observations. When a subject is censored:
#' - Future values are set to NA (not carried forward)
#' - This represents true missingness due to dropout
#' - Methods like IPCW or multiple imputation should be used for analysis
#'
#' @param complete_data Data frame from margot_simulate with "margot_meta" attribute
#' @param censoring_type Character: "built_in" uses stored probabilities,
#'   "custom" uses a custom function
#' @param censoring_function Function for custom censoring (required if censoring_type = "custom").
#'   Should take a data frame and return it with censoring applied.
#' @param apply_process_function Logical. Apply margot_process_longitudinal to create
#'   not-lost indicators? Default: TRUE
#' @param ... Additional arguments passed to margot_process_longitudinal or 
#'   the custom censoring_function
#'
#' @return Data frame with censoring applied and indicators created. The returned
#'   object maintains the "margot_meta" attribute with additional censoring information.
#'   
#' @seealso [margot_process_longitudinal()] for details on indicator creation
#' 
#' @examples
#' # Generate complete data
#' complete <- margot_simulate(n = 1000, waves = 3, 
#'                            censoring = list(rate = 0.2))
#' 
#' # Apply censoring 
#' observed <- apply_censoring_post_hoc(complete)
#' 
#' # Check censoring rates
#' table(observed$t0_not_lost_following_wave)
#' table(observed$t1_not_lost_following_wave)
#' 
#' @export
apply_censoring_post_hoc <- function(
    complete_data,
    censoring_type = c("built_in", "custom"),
    censoring_function = NULL,
    apply_process_function = TRUE,
    ...) {

  censoring_type <- match.arg(censoring_type)
  meta <- attr(complete_data, "margot_meta")

  if (is.null(meta)) {
    stop("complete_data must have margot_meta attribute")
  }

  # create a copy
  censored_data <- complete_data
  n <- nrow(censored_data)
  waves <- meta$waves

  # track who is censored
  alive <- rep(TRUE, n)

  if (censoring_type == "built_in") {
    # use stored censoring probabilities
    censoring_probs <- meta$censoring_probs

    if (is.null(censoring_probs) || length(censoring_probs) == 0) {
      warning("no censoring probabilities stored; returning original data")
      return(complete_data)
    }

    # apply censoring wave by wave
    for (k in seq_along(censoring_probs)) {
      if (k == 1) {
        # t0->t1 censoring
        censored <- as.logical(rbinom(n, 1, censoring_probs[[k]]))
        alive <- !censored

        # set t1 and beyond to NA for censored
        if (any(censored)) {
          for (t in 1:(waves + 1)) {
            vars_to_censor <- grep(paste0("^t", t, "_"), names(censored_data), value = TRUE)
            censored_data[censored, vars_to_censor] <- NA
          }
        }
      } else {
        # tk-1->tk censoring
        t <- k - 1
        still_alive <- which(alive)

        if (length(still_alive) > 0) {
          newly_censored <- as.logical(rbinom(length(still_alive), 1, censoring_probs[[k]][still_alive]))
          alive[still_alive] <- alive[still_alive] & !newly_censored

          # set tk and beyond to NA for newly censored
          newly_censored_idx <- still_alive[newly_censored]
          if (length(newly_censored_idx) > 0) {
            for (future_t in t:(waves + 1)) {
              vars_to_censor <- grep(paste0("^t", future_t, "_"), names(censored_data), value = TRUE)
              censored_data[newly_censored_idx, vars_to_censor] <- NA
            }
          }
        }
      }
    }
  } else {
    # custom censoring function
    if (is.null(censoring_function)) {
      stop("censoring_function required when censoring_type = 'custom'")
    }

    # apply custom censoring
    censored_data <- censoring_function(censored_data, ...)
  }

  # apply processing function to create indicators
  if (apply_process_function) {
    process_args <- list(
      df_wide = censored_data,
      exposure_vars = if (meta$exposure_type %in% c("binary", "continuous")) "a" else NULL,
      scale_continuous = FALSE,
      not_lost_suffix = "not_lost_following_wave",
      preserve_temporal_order = TRUE,
      ...
    )

    censored_data <- do.call(margot_process_longitudinal, process_args)
  }

  # update metadata
  attr(censored_data, "margot_meta") <- meta
  attr(censored_data, "margot_meta")$censoring_applied <- TRUE

  # add summary of actual censoring
  if (apply_process_function) {
    not_lost_cols <- grep("not_lost_following_wave$", names(censored_data), value = TRUE)
    censoring_summary <- list()
    for (col in not_lost_cols) {
      censoring_summary[[col]] <- table(censored_data[[col]])
    }
    attr(censored_data, "margot_meta")$censoring_summary <- censoring_summary
  }

  censored_data
}